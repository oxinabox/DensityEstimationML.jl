{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Intro\n",
    "\n",
    "This is inspired by \n",
    "Article (likas2001probability) Likas, A. Probability density estimation using artificial neural networks Computer physics communications, Elsevier, 2001, 135, 167-175\n",
    "\n",
    "But rather than estimating the working with a network, we will instead work with its derivitive.\n",
    "This will let us replace their integration with a derivative.\n",
    "\n",
    "Note that this method only works for compact supports\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They use the PDF is given by $$p_h(x,p) = \\dfrac{h(x,p)}{\\int_S h(z,p) dz}$$\n",
    "and in their case $h=N(x,p)$  a neural network with weight and bias parameters $p$.\n",
    "Where $S$ is a compact support. (That means bounded)\n",
    "\n",
    "\n",
    "But if instead we say $h=\\frac{\\partial N(x,p)}{\\partial x}$,\n",
    "\n",
    "then $$p_h(x,p) = \\dfrac{h(x,p)}{\\int_S h(z,p)}=\\dfrac{\\frac{\\partial N(x,p)}{\\partial x}}{N(max(S),p) - N(min(S), p)}$$\n",
    "\n",
    "The denominator is ofcourse more complex for non-1D values of S.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function given is the negative log-likelihood of the set of training samples $X$\n",
    "$$L(p) = -\\sum_{\\forall x \\in X} ln(h(x,p))  + |X| ln(\\int_S h(z,p) dx)$$\n",
    "\n",
    "Which befomes:\n",
    "\n",
    "$$L(p) = -\\sum_{\\forall x \\in X} log(\\frac{\\partial N(x,p)}{\\partial x})  + |X|(ln(N(max(S),p)-N(min(S),p)) dx$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "using IJulia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using TensorFlow\n",
    "using Distributions\n",
    "using StatsBase\n",
    "using StaticArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "only (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DensityEstimationML\n",
    "function only(itr)\n",
    "    state = start(itr)\n",
    "    val,state = next(itr, state)\n",
    "    @assert(done(itr,state))\n",
    "    return val\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dytn = <Tensor yt:1 shape=unknown dtype=Float32>\n",
      "t_col = "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-20 20:44:07.097554: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-20 20:44:07.097584: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-20 20:44:07.097590: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-20 20:44:07.300260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2017-09-20 20:44:07.300763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \n",
      "name: GeForce GTX TITAN X\n",
      "major: 5 minor: 2 memoryClockRate (GHz) 1.076\n",
      "pciBusID 0000:01:00.0\n",
      "Total memory: 11.91GiB\n",
      "Free memory: 11.78GiB\n",
      "2017-09-20 20:44:07.300776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \n",
      "2017-09-20 20:44:07.300781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \n",
      "2017-09-20 20:44:07.300792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Tensor t_1:1 shape=(?) dtype=Float32>\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mKeyError: key Any not found\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mKeyError: key Any not found\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mgetindex\u001b[22m\u001b[22m at \u001b[1m./dict.jl:474\u001b[22m\u001b[22m [inlined]",
      " [2] \u001b[1mjl_to_df_type\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Type{T} where T\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/core.jl:1355\u001b[22m\u001b[22m",
      " [3] \u001b[1msetindex!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.NodeDescription, ::DataType, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/core.jl:24\u001b[22m\u001b[22m",
      " [4] \u001b[1m(::TensorFlow.Ops.##352#353{Void,DataType})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/ops/imported_ops.jl:3448\u001b[22m\u001b[22m",
      " [5] \u001b[1mwith_op_name\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Ops.##352#353{Void,DataType}, ::Void, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/core.jl:972\u001b[22m\u001b[22m",
      " [6] \u001b[1m#const_#351\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Void, ::Void, ::Type{T} where T, ::Function\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/ops/imported_ops.jl:3442\u001b[22m\u001b[22m",
      " [7] \u001b[1m(::TensorFlow.Ops.#kw##const_)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::TensorFlow.Ops.#const_\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m",
      " [8] \u001b[1m#constant#169\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Void, ::Array{Any,1}, ::Function, ::Void\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/ops/sequences.jl:14\u001b[22m\u001b[22m",
      " [9] \u001b[1mconvert\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Type{TensorFlow.Tensor{Any}}, ::Void\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/core.jl:1214\u001b[22m\u001b[22m",
      " [10] \u001b[1m(::TensorFlow.Ops.##1461#1462)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/ops/imported_ops.jl:14529\u001b[22m\u001b[22m",
      " [11] \u001b[1mwith_op_name\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Ops.##1461#1462, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/core.jl:972\u001b[22m\u001b[22m",
      " [12] \u001b[1m#identity#1460\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Function, ::Void\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/ops/imported_ops.jl:14527\u001b[22m\u001b[22m",
      " [13] \u001b[1m(::TensorFlow.Ops.#kw##identity)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::TensorFlow.Ops.#identity, ::Void\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m",
      " [14] \u001b[1m(::TensorFlow.###12#13#16{TensorFlow.Ops.#identity,String})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::Void, ::Vararg{Void,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/meta.jl:72\u001b[22m\u001b[22m",
      " [15] \u001b[1m(::TensorFlow.#kw###12#15)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::TensorFlow.##12#15, ::Void, ::Vararg{Void,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m",
      " [16] \u001b[1mDensityEstimationML.NeuralDensityEstimator\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Int64,1}, ::SVector{2,Float64}, ::SVector{2,Float64}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/DensityEstimationML/src/network.jl:77\u001b[22m\u001b[22m",
      " [17] \u001b[1mDensityEstimationML.NeuralDensityEstimator\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Int64,1}, ::DensityEstimationML.GenerateDatasets.RectangularInterval{SVector{2,Float64}}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/DensityEstimationML/src/network.jl:3\u001b[22m\u001b[22m",
      " [18] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "dataset = GenerateDatasets.Likas3()\n",
    "data = original_sample(dataset)\n",
    "est = NeuralDensityEstimator([64], approximate_support(dataset))\n",
    "sess = est.sess\n",
    "run(sess, est.pdf, Dict(est.t=>[0.1 0.1; 0.1 0.1; 0.3 0.6]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: imported binding for gr overwritten in module Main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(Ptr{Void} @0x0000000007300000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr=get_def_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape[?]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients(gr[\"yt\"], gr[\"t\"])[1,:] |> get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1 2 3; 4 54 6][1,:ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add\n",
      "Add_2\n",
      "Add_3\n",
      "Cast\n",
      "Cast_2\n",
      "Cast_3\n",
      "Cast_4\n",
      "Cast_5\n",
      "Cast_6\n",
      "Const_4\n",
      "Const_5\n",
      "Exp\n",
      "Exp_2\n",
      "Exp_3\n",
      "MatMul\n",
      "MatMul_2\n",
      "MatMul_3\n",
      "MatMul_4\n",
      "MatMul_5\n",
      "MatMul_6\n",
      "Sigmoid\n",
      "Sigmoid_2\n",
      "Sigmoid_3\n",
      "Sub\n",
      "W_2\n",
      "W_2/Assign\n",
      "W_2/Assign/Const\n",
      "W_2_squared\n",
      "W_3\n",
      "W_3/Assign\n",
      "W_3/Assign/Const_3\n",
      "W_3_squared\n",
      "b_2\n",
      "b_2/Assign\n",
      "b_2/Assign/Const_2\n",
      "denominator\n",
      "denominator/range\n",
      "denominator/rank\n",
      "gradients/Const\n",
      "gradients/Fill\n",
      "gradients/Shape\n",
      "smax\n",
      "smin\n",
      "t\n",
      "t_1\n",
      "t_1/Const_6\n",
      "t_1/Const_7\n",
      "t_1/Sub_2\n",
      "ysmax\n",
      "ysmin\n",
      "yt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51-element Array{Void,1}:\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " ⋮      \n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing\n",
       " nothing"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println.(sort(gr |> keys |> collect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function returning a function that will display a running plot.\n",
    "WARNING: Introducting or removing any variables is not supported.\n",
    "And will silently error.\n",
    "\"\"\"\n",
    "function running_plot()\n",
    "    epochs = Int[]\n",
    "    record = Dict()\n",
    "    function inner(epoch, vars::Associative)\n",
    "        for (var, values) in vars\n",
    "            value = only(values) #Incase it was an array\n",
    "            past = get!(record, var) do\n",
    "                typeof(value)[]\n",
    "            end\n",
    "            push!(past, value)\n",
    "        end\n",
    "        push!(epochs, epoch)\n",
    "        \n",
    "        IJulia.clear_output(true)\n",
    "        plot(epochs, hcat(values(record)...); label=hcat(keys(vars)...), layout=length(vars)) |> IJulia.display       \n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function demonstration_plot(est, dataset, data, args...; kwargs...)\n",
    "    X = minimum(approximate_support(dataset)) : 0.01 : maximum(approximate_support(dataset))\n",
    "    @show typeof(data)\n",
    "    println(\"True loglikelihood      = $(loglikelihood(dataset, data))\")\n",
    "    println(\"Estimated loglikelihood = $(loglikelihood(est, data))\")\n",
    "    plot([X], [pdf(est,X), data],\n",
    "        #xlims= approximate_support(dataset),\n",
    "        xlims= (first(X), last(X)),\n",
    "        seriestype = [:path :histogram],\n",
    "        layout=(2,1),\n",
    "        legend=false,\n",
    "        nbins=[1  length(data)÷10],\n",
    "        args...; kwargs...\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function demo(dataset, layers, epochs=20_000; max_conditioning_epochs=2000)\n",
    "    data = original_sample(dataset)\n",
    "    @show loglikelihood(dataset, data)\n",
    "    est = NeuralDensityEstimator(layers, approximate_support(dataset))\n",
    "\n",
    "    condition!(est; max_epochs = max_conditioning_epochs)\n",
    "    println(\"Conditioning Done\")\n",
    "    Plots.gr()\n",
    "    fit!(est, data; epochs=epochs, callback=running_plot())\n",
    "    println(\"Fitting Done\")\n",
    "    plotly()\n",
    "    demonstration_plot(est, dataset, data) |> IJulia.display\n",
    "    \n",
    "    est    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est=demo(GenerateDatasets.Likas1(), [64, 64, 256], 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let \n",
    "    sess = Session(Graph())\n",
    "    X=constant([1.0,2,3])\n",
    "    y=Ops.mul(X,X)\n",
    "    @show y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglikelihood(GenerateDatasets.Likas1(), [2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GenerateDatasets.Likas1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(component_weights(est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo(GenerateDatasets.Likas2(), [64,64], 20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo(GenerateDatasets.MagdonIsmailAndAtiya(), [32], 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo(Arcsine(1,4), [64,64], 20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = GenerateDatasets.Likas3()\n",
    "data = original_sample(dataset)\n",
    "est = NeuralDensityEstimator([64], approximate_support(GenerateDatasets.Likas3()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: GenerateDatasets not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: GenerateDatasets not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loglikelihood(dataset, data) = 16094.379124341185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16094.379124341185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show loglikelihood(dataset, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-20 20:26:25.280835: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-20 20:26:25.280863: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-20 20:26:25.280869: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-09-20 20:26:25.485456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2017-09-20 20:26:25.485961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \n",
      "name: GeForce GTX TITAN X\n",
      "major: 5 minor: 2 memoryClockRate (GHz) 1.076\n",
      "pciBusID 0000:01:00.0\n",
      "Total memory: 11.91GiB\n",
      "Free memory: 11.78GiB\n",
      "2017-09-20 20:26:25.485974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \n",
      "2017-09-20 20:26:25.485979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \n",
      "2017-09-20 20:26:25.485991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mOn worker 2:\n\u001b[91mPython error: 'NoneType' object has no attribute 'dtype'\u001b[39m\npy_gradients at /home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/py.jl:45\n#9 at /home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/TensorFlow.jl:171\n#110 at ./distributed/process_messages.jl:275 [inlined]\nrun_work_thunk at ./distributed/process_messages.jl:56\nrun_work_thunk at ./distributed/process_messages.jl:65 [inlined]\n#96 at ./event.jl:73\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mOn worker 2:\n\u001b[91mPython error: 'NoneType' object has no attribute 'dtype'\u001b[39m\npy_gradients at /home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/py.jl:45\n#9 at /home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/TensorFlow.jl:171\n#110 at ./distributed/process_messages.jl:275 [inlined]\nrun_work_thunk at ./distributed/process_messages.jl:56\nrun_work_thunk at ./distributed/process_messages.jl:65 [inlined]\n#96 at ./event.jl:73\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1m#remotecall_wait#146\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::Function, ::Base.Distributed.Worker\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./distributed/remotecall.jl:382\u001b[22m\u001b[22m",
      " [2] \u001b[1mremotecall_wait\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Function, ::Base.Distributed.Worker\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./distributed/remotecall.jl:373\u001b[22m\u001b[22m",
      " [3] \u001b[1m#remotecall_wait#149\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::Function, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./distributed/remotecall.jl:394\u001b[22m\u001b[22m",
      " [4] \u001b[1mremotecall_wait\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Function, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./distributed/remotecall.jl:394\u001b[22m\u001b[22m",
      " [5] \u001b[1meval\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::Any\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./boot.jl:235\u001b[22m\u001b[22m",
      " [6] \u001b[1mgradients\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Void, ::Array{TensorFlow.Tensor{Float32},1}, ::Void\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/core.jl:1511\u001b[22m\u001b[22m",
      " [7] \u001b[1mgradients\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/core.jl:1526\u001b[22m\u001b[22m [inlined] (repeats 2 times)",
      " [8] \u001b[1m(::TensorFlow.###8#9#11{TensorFlow.#gradients})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::Void, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/TensorFlow/src/meta.jl:67\u001b[22m\u001b[22m",
      " [9] \u001b[1mDensityEstimationML.NeuralDensityEstimator\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Int64,1}, ::SVector{2,Float64}, ::SVector{2,Float64}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/DensityEstimationML/src/network.jl:73\u001b[22m\u001b[22m",
      " [10] \u001b[1mDensityEstimationML.NeuralDensityEstimator\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Int64,1}, ::DensityEstimationML.GenerateDatasets.RectangularInterval{SVector{2,Float64}}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/home/uniwa/students2/students/20361362/linux/.julia/v0.6/DensityEstimationML/src/network.jl:3\u001b[22m\u001b[22m",
      " [11] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "est = NeuralDensityEstimator([64], approximate_support(GenerateDatasets.Likas3()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition!(est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit!(est, data'; epochs=10_000, callback=running_plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fit!(est, data; epochs=10_000, callback=running_plot())\n",
    "println(\"Fitting Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: est not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: est not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "sess = est.sess\n",
    "run(sess, est.pdf, Dict(est.t=>[0.1 0.1; 0.1 0.1; 0.3 0.6]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = est.sess\n",
    "run(sess, sess.graph[\"numerator\"], Dict(est.t=>[0.1 0.1; 0.1 0.1; 0.3 0.6]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(sess, gather(constant(data), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    meshgrid(xs, ys, zfun)\n",
    "\n",
    "Evalates `zfun(x,y)` at each point in `xs`, and `ys`.\n",
    "Returns 3 vectors, a list of x points a list of y points and the value of z at that point.\n",
    "\"\"\"\n",
    "function meshgrid(xs, ys, zfun) \n",
    "    # There is a cute generalisation of this with a `@generated` function\n",
    "    xpoints = eltype(xs)[]\n",
    "    ypoints = eltype(ys)[]\n",
    "    zpoints = typeof(zfun(xs[1],ys[1]))[]\n",
    "    sizehint!.([xpoints, ypoints, zpoints], length(xs)*length(ys))\n",
    "    for x in xs, y in ys\n",
    "        push!(xpoints,x)\n",
    "        push!(ypoints,y)\n",
    "        push!(zpoints,zfun(x,y))\n",
    "    end\n",
    "    \n",
    "    xpoints, ypoints, zpoints\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=-0.1:0.01:0.3\n",
    "Y=-0.1:0.01:0.3\n",
    "scatter3d(meshgrid(X,Y, (x,y)->pdf(est, [x,y]))...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf(est, SMatrix{1,2}([0.1 0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size([0.1 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?SArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
